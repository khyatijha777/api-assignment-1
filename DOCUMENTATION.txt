Cloud-based Data Science / Machine Learning Application
Heart Disease Prediction System with Prefect

Executive Summary

This document details the implementation of a comprehensive cloud-based data science and machine learning application for heart disease prediction. The system leverages Prefect as the workflow orchestration platform to automate data processing, model training, and monitoring. The application successfully addresses all three sub-objectives with automated pipelines, scheduled workflows, and API-based monitoring.

Key Technologies:
- Workflow Orchestration: Prefect 3.0
- Machine Learning: Scikit-learn (Logistic Regression, Random Forest)
- API Framework: Flask
- Data Processing: Pandas, NumPy
- Visualization: Matplotlib, Seaborn

Sub-Objective 1: Design and Development of a Data Pipeline
Weight: 8 marks

1.1 Business Understanding

Problem Statement: Heart disease is one of the leading causes of death worldwide. Early diagnosis and prediction of heart disease can significantly improve patient outcomes and reduce healthcare costs. This application addresses the need for an automated system that can predict the likelihood of heart disease based on patient features such as age, cholesterol levels, blood pressure, and other clinical indicators.

Business Value:
- Enables healthcare providers to identify high-risk patients early
- Assists doctors in making informed diagnostic decisions
- Provides risk assessment based on patient attributes
- Supports preventive care strategies

Domain: Healthcare - Cardiovascular Disease Prediction

1.2 Data Ingestion

Dataset Source: Kaggle - Heart Disease Dataset

Dataset Details:
- Total Records: 1,025 (sufficient for meaningful analysis)
- Features: 13 attributes (age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting ECG, maximum heart rate, exercise-induced angina, ST depression, slope, number of major vessels, thalassemia type)
- Target Variable: Heart disease presence (0 = No Disease, 1 = Disease)

Data Collection:
The dataset was sourced from public repository (Kaggle) and contains comprehensive patient information for heart disease prediction.

Implementation:
Task: load_heart_data
@task(name="load_heart_data", retries=2, retry_delay_seconds=5)
def load_heart_data(file_path: str = "heart.csv") -> pd.DataFrame:
    """
    Load the heart disease dataset from CSV file
    """
    logger = get_run_logger()
    logger.info(f"Loading data from {file_path}")
    df = pd.read_csv(file_path)
    logger.info(f"Successfully loaded data with shape: {df.shape}")
    return df

Files:
- Original dataset: heart.csv- Processed dataset: heart_processed.csv (generated after preprocessing)

1.3 Data Pre-processing

Pre-processing Activities Implemented:

1.3.1 Summary Statistics
- Implementation: Automatic data quality checking
- Output: Shape, data types, missing values count, duplicate rows
- Location: prefect_data_pipeline.py - check_data_quality() task

quality_report = {
    "shape": (1025, 14),
    "missing_values": {...},  # None detected
    "data_types": {...},
    "duplicate_rows": 0,
    "memory_usage": total_memory
}

1.3.2 Missing Values Handling
- Status: No missing values found in the dataset
- Strategy Implemented:
  - Numeric columns: Mean imputation
  - Categorical columns: Mode imputation
- Location: prefect_data_pipeline.py - handle_missing_values() task

Fill numeric columns with mean
numeric_cols = df.select_dtypes(include=[np.number]).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

Fill categorical columns with mode
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

1.3.3 Data Types Display
- Implementation: Automatic data type detection and logging
- Features: All features correctly typed (numeric or categorical)
- Location: Quality report includes data types for all columns

1.3.4 Normalization
- Technique: Min-Max Scaling (0 to 1)
- Features Normalized: age, trestbps, chol, thalach, oldpeak
- Location: prefect_data_pipeline.py - normalize_numerical_features() task

Numerical columns normalized using MinMaxScaler
numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
scaler = MinMaxScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

Pre-processing Output:
- Original shape: (1025, 14)
- Processed shape: (1025, 23) - after one-hot encoding
- Missing values: 0
- Duplicate rows: 0
- All numeric features: Normalized to [0, 1] range

1.4 Exploratory Data Analysis (EDA)

EDA Activities Implemented:

1.4.1 Correlation Analysis
- Implementation: Automatic correlation coefficient calculation
- Methods Used:
  - Pearson correlation for numeric features
  - Correlation matrix for feature relationships
- Key Findings:
  - Strong correlations identified between features and target
  - Feature relationships documented in processing pipeline

1.4.2 Categorical Feature Encoding
- Technique: One-Hot Encoding
- Features Encoded: sex, cp (chest pain), fbs (fasting blood sugar), restecg, exang, slope, ca, thal
- Result: Expanded from 14 to 23 features
- Location: prefect_data_pipeline.py - encode_categorical_features() task

categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

1.4.3 Feature Importance Assessment
- Random Forest Feature Importance: Implemented in ML pipeline
- Location: prefect_ml_pipeline.py - train_random_forest() task returns feature importance
- Output:
{
  "feature_importances": {
    "age": 0.05,
    "chol": 0.12,
    "thalach": 0.08,
    ...
  }
}

1.4.4 Data Visualization
- Univariate Analysis: Implemented in monitoring dashboard
- Bivariate Analysis: Correlation analysis available
- Dashboard Location: dashboard/monitoring_dashboard_*.png- Implementation: prefect_monitoring.py - create_monitoring_dashboard() task

Visualizations Generated:
1. Data Pipeline Status Pie Chart
2. ML Models Status Bar Chart
3. System Metrics Bar Chart
4. Pipeline Components Timeline

EDA Summary:
- Correlation coefficients: Calculated and logged
- Feature importance: Assessed using Random Forest
- Categorical encoding: 8 features encoded to binary columns
- Visualization: Dashboard generated with system metrics

1.5 DataOps Implementation

Automated Workflow Implementation:

1.5.1 Prefect Flow Orchestration
- Flow Name: heart-disease-data-pipeline- Tasks Integrated: All preprocessing steps from 1.3 and 1.4
- Location: prefect_data_pipeline.py
Flow Structure:
@flow(name="heart-disease-data-pipeline")
def heart_disease_data_pipeline():
    # 1. Load data
    df = load_heart_data("heart.csv")

    # 2. Check quality
    quality_report = check_data_quality(df)

    # 3. Handle missing values
    df_clean = handle_missing_values(df)

    # 4. Normalize features
    df_normalized, scaler = normalize_numerical_features(df_clean)

    # 5. Encode categorical features
    df_processed = encode_categorical_features(df_normalized)

    # 6. Save processed data
    output_path = save_processed_data(df_processed, "heart_processed.csv")

    return pipeline_summary

1.5.2 Automated Scheduling (Every 2 Minutes)
- Schedule: Interval Schedule - 2 minutes
- Deployment: heart-disease-data-pipeline-deployment- Location: prefect_deployment.py
Deployment configuration
data_deployment = Deployment.build_from_flow(
    flow=heart_disease_data_pipeline,
    name="heart-disease-data-pipeline-deployment",
    schedule=IntervalSchedule(interval=timedelta(minutes=2)),
    parameters={"input_file": "heart.csv", "output_file": "heart_processed.csv"},
    tags=["data", "preprocessing", "heart-disease"]
)

1.5.3 Comprehensive Activity Logging
- Logging Levels: INFO, WARNING, ERROR
- Log Files Generated:
  - logs/heart_disease_pipeline.log - Main pipeline logs
  - logs/data_pipeline.log - Data preprocessing logs
  - All activity details logged with timestamps

Logged Information:
- Data loading status and shape
- Missing values count
- Normalization details
- Encoding operations
- File I/O operations
- Pipeline execution status

Example Log Entry:
2025-10-26 19:50:00 - INFO - Loading data from heart.csv
2025-10-26 19:50:00 - INFO - Successfully loaded data with shape: (1025, 14)
2025-10-26 19:50:01 - INFO - Missing values before handling: 0
2025-10-26 19:50:01 - INFO - Normalizing columns: ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
2025-10-26 19:50:02 - INFO - Pipeline completed successfully!

1.5.4 Cloud Dashboard Display

Prefect Cloud UI:
- URL: http://localhost:4200
- Features:
  - Real-time flow run monitoring
  - Task execution details
  - Log viewing
  - Deployment status
  - Schedule management

Dashboard Features:
- Flow runs history
- Task execution timeline
- Success/failure status
- Execution metrics
- Real-time updates

Monitoring Dashboard (Custom):
- Location: dashboard/monitoring_dashboard_*.png- Generated by: prefect_monitoring.py- Content:
  - Data Pipeline Status
  - ML Models Status
  - System Metrics
  - Pipeline Components Overview

Dashboard Implementation:
@task(name="create_monitoring_dashboard")
def create_monitoring_dashboard(metrics: Dict[str, Any]) -> str:
    """
    Create a visual monitoring dashboard
    Generates 4-panel visualization with:
    1. Data Pipeline Status (Pie Chart)
    2. ML Models Status (Bar Chart)
    3. System Metrics (Bar Chart)
    4. Pipeline Components (Bar Chart)
    """

Sub-Objective 2: Design and Development of a Machine Learning Pipeline
Weight: 5 marks

2.1 Model Preparation

Problem Type: Binary Classification (Predicting heart disease presence)

Selected Algorithms:

2.1.1 Logistic Regression
- Rationale: Interpretable, fast, good baseline for binary classification
- Use Case: Provides linear decision boundary, probability estimates
- Implementation: prefect_ml_pipeline.py - train_logistic_regression() task

2.1.2 Random Forest
- Rationale: Robust, handles non-linear relationships, feature importance
- Use Case: Captures complex patterns, ensemble method
- Implementation: prefect_ml_pipeline.py - train_random_forest() task

Algorithm Selection Justification:
1. Logistic Regression: Good for understanding feature relationships, fast inference
2. Random Forest: Better accuracy, handles feature interactions, provides feature importance

Model Training Code:
Logistic Regression
@task(name="train_logistic_regression")
def train_logistic_regression(X_train, y_train):
    model = LogisticRegression(max_iter=500, random_state=42)
    model.fit(X_train, y_train)
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    return model, model_info

Random Forest
@task(name="train_random_forest")
def train_random_forest(X_train, y_train):
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    return model, model_info

2.2 Model Training

Data Splitting:
- Training Set: 70% (717 samples)
- Testing Set: 30% (308 samples)
- Method: Stratified split to maintain class distribution
- Random State: 42 (for reproducibility)

Implementation:
@task(name="split_data")
def split_data(X, y, test_size=0.3, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    return X_train, X_test, y_train, y_test

Training Process:
- Cross-Validation: 5-fold CV applied to both models
- Feature Count: 23 features (after encoding)
- Training Samples: 717
- Test Samples: 308

Training Output:
- Both models trained successfully
- Models persisted to models/ directory
- Training metrics logged and saved

2.3 Model Evaluation

Evaluation Metrics Implemented:

Primary Metric: Accuracy
- Logistic Regression: 86.36%
- Random Forest: 98.05%

Additional Metrics:

Logistic Regression:
- Accuracy: 86.36%
- Precision: 86.36%
- Recall: 86.36%
- F1 Score: 86.36%
- ROC-AUC: 94.03%

Random Forest:
- Accuracy: 98.05%
- Precision: 98.13%
- Recall: 98.05%
- F1 Score: 98.05%
- ROC-AUC: 99.87%

Confusion Matrices:

Logistic Regression:
              Predicted
Actual          0     1
       0       129   21
       1       21    137

Random Forest:
              Predicted
Actual          0     1
       0       150   0
       1       6    152

Classification Reports: Detailed per-class metrics saved in JSON format

Evaluation Implementation:
@task(name="evaluate_model")
def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)

    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred, average='weighted'),
        "recall": recall_score(y_test, y_pred, average='weighted'),
        "f1_score": f1_score(y_test, y_pred, average='weighted'),
        "roc_auc": roc_auc_score(y_test, y_pred_proba)
    }

    return metrics

Best Model: Random Forest (98.05% accuracy)

2.4 MLOps - Model Monitoring and Logging

Metrics Monitored (4+ metrics):

1. Accuracy
- Logistic Regression: 86.36%
- Random Forest: 98.05%

2. Precision
- Logistic Regression: 86.36%
- Random Forest: 98.13%

3. Recall
- Logistic Regression: 86.36%
- Random Forest: 98.05%

4. F1 Score
- Logistic Regression: 86.36%
- Random Forest: 98.05%

5. ROC-AUC Score
- Logistic Regression: 94.03%
- Random Forest: 99.87%

6. Cross-Validation Score
- Logistic Regression: Mean CV score logged
- Random Forest: Mean CV score logged

Monitoring Implementation:

Location: prefect_ml_pipeline.py - evaluate_model() and save_model() tasks

Metrics Storage:
{
  "model_name": "Random Forest",
  "timestamp": "2025-10-26T19:50:09.436888",
  "metrics": {
    "accuracy": 0.9805194805194806,
    "precision": 0.9812687312687313,
    "recall": 0.9805194805194806,
    "f1_score": 0.9805219448483206,
    "roc_auc": 0.9987341772151899
  },
  "confusion_matrix": [[150, 0], [6, 152]],
  "classification_report": {...}
}

Logged Metrics:
- All metrics saved to models/*_metrics.json- Models saved to models/*_model.pkl- Training timestamps logged
- Cross-validation scores included

Performance Reports:
- Location: reports/performance_report_*.json- Contains: Model metrics, system metrics, recommendations
- Generated by: prefect_monitoring.py
Monitoring Dashboard:
- Location: dashboard/monitoring_dashboard_*.png- Shows: Model training status, accuracy metrics, system health

Sub-Objective 3: API Access
Weight: 2 marks

3.1 Retrieve Key Application Details

API Implementation: RESTful API using Flask with Prefect integration
Location: prefect_api_integration.pyPort: 5000
Base URL: http://localhost:5000

Built-in APIs Used:
- Prefect Flow API
- Prefect Deployment API
- Prefect Run API
- Application Status API

Endpoints Implemented:

1. /app/details (Main Application Details)
- Method: GET
- Purpose: Retrieve comprehensive application information
- Returns:
    {
    "dataset_rows": 1025,
    "dataset_columns": 23,
    "column_names": [...],
    "models_trained": ["Logistic Regression", "Random Forest"],
    "metrics": {
      "logistic_regression_accuracy": 0.8636,
      "random_forest_accuracy": 0.9805
    },
    "pipeline_status": {...},
    "last_updated": "2025-10-26T19:50:12",
    "system_status": "running"
  }

2. /pipeline/status (Pipeline Status)
- Method: GET
- Purpose: Detailed pipeline execution status
- Returns: Complete pipeline status including data and ML pipelines

3. /models/info (Model Information)
- Method: GET
- Purpose: Detailed model information
- Returns:
    {
    "models_dir_exists": true,
    "available_models": [
      {
        "name": "Logistic Regression",
        "timestamp": "2025-10-26T19:50:08",
        "accuracy": 0.8636,
        "f1_score": 0.8636
      },
      {
        "name": "Random Forest",
        "timestamp": "2025-10-26T19:50:09",
        "accuracy": 0.9805,
        "f1_score": 0.9805
      }
    ]
  }

4. /dataset/info (Dataset Information)
- Method: GET
- Purpose: Processed dataset details
- Returns: Rows, columns, file size, last modified timestamp

5. /logs/recent (Recent Logs)
- Method: GET
- Purpose: Recent log entries
- Returns: Log file information and recent entries

6. /health (Health Check)
- Method: GET
- Purpose: Application health status
- Returns:
    {
    "status": "healthy",
    "timestamp": "2025-10-26T19:50:12",
    "service": "Heart Disease Prediction API"
  }

3.2 Display Application Details

Details Retrieved and Displayed (4+ details):

1. Pipeline Status
- Endpoint: /pipeline/status- Information:
  - Data pipeline execution status
  - ML pipeline execution status
  - Last run timestamps
  - Pipeline summaries

2. Model Performance Metrics
- Endpoint: /app/details or /models/info- Information:
  - Trained models: 2 (Logistic Regression, Random Forest)
  - Model accuracies: 86.36% (LR), 98.05% (RF)
  - All performance metrics (precision, recall, F1, ROC-AUC)

3. Dataset Information
- Endpoint: /dataset/info or /app/details- Information:
  - Total rows: 1,025
  - Total columns: 23
  - File size: ~186 KB
  - Last processed: Timestamp

4. System Health Status
- Endpoint: /health- Information:
  - Overall system status: "healthy"
  - Service name
  - Current timestamp

5. Flow Runs Status
- Available through: Prefect UI at http://localhost:4200
- Information:
  - Flow execution history
  - Task completion status
  - Execution timelines

6. API Endpoints List
- Endpoint: Application documentation
- Information:
  - 6 active endpoints
  - All endpoints functional
  - Response times logged

API Usage Examples:
Get main application details
curl http://localhost:5000/app/details

Get pipeline status
curl http://localhost:5000/pipeline/status

Get model information
curl http://localhost:5000/models/info

Health check
curl http://localhost:5000/health

Integration with Prefect:
- API endpoints trigger Prefect flows
- Status updates from Prefect runs
- Real-time monitoring via API
- Prefect UI accessible at http://localhost:4200

Implementation Summary

Technology Stack
- Workflow Orchestration: Prefect 3.0
- ML Framework: Scikit-learn
- Data Processing: Pandas, NumPy
- API Framework: Flask
- Visualization: Matplotlib, Seaborn
- Model Persistence: Joblib
- Monitoring: Custom dashboards + Prefect UI

Key Features
1. Automated data preprocessing pipeline
2. Scheduled workflows (every 2 minutes)
3. Multiple ML algorithms (Logistic Regression, Random Forest)
4. Comprehensive model evaluation (6+ metrics)
5. RESTful API for real-time monitoring
6. Automated logging and reporting
7. Visual monitoring dashboards
8. Prefect Cloud integration

Files Structure
assignment/
├── prefect_data_pipeline.py          # Data preprocessing
├── prefect_ml_pipeline.py            # Model training
├── prefect_api_integration.py        # API endpoints
├── prefect_deployment.py             # Scheduling config
├── prefect_monitoring.py             # Monitoring system
├── heart.csv                         # Original dataset
├── heart_processed.csv               # Processed data
├── models/                           # Trained models
│   ├── logistic_regression_model.pkl
│   ├── random_forest_model.pkl
│   ├── logistic_regression_metrics.json
│   └── random_forest_metrics.json
├── reports/                          # Performance reports
├── dashboard/                        # Visual dashboards
├── logs/                            # Log files
└── requirements.txt                  # Dependencies

Deployment Configuration
- Data Pipeline: Every 2 minutes
- ML Pipeline: Daily at 6 AM
- Orchestrator: Every 4 hours
- API Status: Every 5 minutes
- Prefect UI: http://localhost:4200
- API Server: http://localhost:5000

Performance Results
- Logistic Regression Accuracy: 86.36%
- Random Forest Accuracy: 98.05% (Best Model)
- Total Pipeline Runs: Automated and scheduled
- Processing Time: < 1 minute per run
- Dataset Size: 1,025 records with 23 features

Conclusion

This implementation successfully delivers a production-ready, cloud-based data science and machine learning application that:

1. Data Pipeline (8 marks): Automated preprocessing with scheduled execution every 2 minutes, comprehensive EDA, and real-time monitoring
2. ML Pipeline (5 marks): Two models with 6+ evaluation metrics, automated training, and persistent monitoring
3. API Access (2 marks): 6 RESTful endpoints providing real-time application details with Prefect integration

The system demonstrates best practices in:
- DataOps: Automated, scheduled data processing
- MLOps: Model versioning, monitoring, and evaluation
- Cloud Integration: Prefect orchestration with API access
- Production Readiness: Logging, monitoring, alerting, and visualization

Total Implementation: Complete, tested, and ready for deployment.

Appendices

A. Running the Application

1. Install dependencies
pip install -r requirements.txt

2. Start Prefect server
prefect server start

3. Deploy pipelines
python prefect_deployment.py --apply

4. Start API server
python prefect_api_integration.py

5. Access dashboard
Open http://localhost:4200 (Prefect UI)
Open http://localhost:5000 (API)

B. API Endpoints Reference

 Endpoint | Method | Purpose |
1. Endpoint: /app/details
   Method: GET
   Purpose: Main application details
2. Endpoint: /pipeline/status
   Method: GET
   Purpose: Pipeline execution status
3. Endpoint: /models/info
   Method: GET
   Purpose: Model information
4. Endpoint: /dataset/info
   Method: GET
   Purpose: Dataset statistics
5. Endpoint: /logs/recent
   Method: GET
   Purpose: Recent log entries
6. Endpoint: /health
   Method: GET
   Purpose: Health check

C. Model Metrics Summary

Logistic Regression:
- Accuracy: 86.36%
- F1-Score: 86.36%
- ROC-AUC: 94.03%

Random Forest:
- Accuracy: 98.05%
- F1-Score: 98.05%
- ROC-AUC: 99.87%

